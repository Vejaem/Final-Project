{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp_stopwords.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BR7kMdb2n6CD","executionInfo":{"status":"ok","timestamp":1611102631831,"user_tz":300,"elapsed":20585,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}},"outputId":"4c80a584-9d10-4671-806c-3879cac88167"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.1'\n","spark_version = 'spark-3.0.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"06xVSBkgMm33"},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qL4Sh8Jfn1qg"},"source":["# import stopwords library\n","from pyspark.ml.feature import StopWordsRemover"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"HqapKjw4n1qr","outputId":"0b379348-7008-44c6-f28e-56434e754374"},"source":["# Create DataFrame\n","sentenceData = spark.createDataFrame([\n","    (0, [\"Big\", \"data\", \"is\", \"super\", \"powerful\"]),\n","    (1, [\"This\", \"is\", \"going\", \"to\", \"be\", \"epic\"])\n","], [\"id\", \"raw\"])\n","\n","sentenceData.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|                 raw|\n","+---+--------------------+\n","|  0|[Big, data, is, s...|\n","|  1|[This, is, going,...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hM4scETAn1qw"},"source":["# Instantiate Remover\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"g_-vdLIDn1q0","outputId":"c6ef352e-8761-4e41-97b6-798815ff3157"},"source":["# Transform and show data\n","remover.transform(sentenceData).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hEPteR-3oADS"},"source":[""],"execution_count":null,"outputs":[]}]}