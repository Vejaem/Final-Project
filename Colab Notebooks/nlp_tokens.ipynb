{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp_tokens.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ba5cHmgjpn7","executionInfo":{"status":"ok","timestamp":1611099897200,"user_tz":300,"elapsed":15436,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}},"outputId":"fb2dbf65-0801-4f2f-93e4-947137a31ace"},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.0.1'\n","spark_version = 'spark-3.0.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:3 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","Hit:8 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6rIceXnyCFL0","executionInfo":{"status":"ok","timestamp":1611099906349,"user_tz":300,"elapsed":9498,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"NLPTokens\").getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyUv4abqjkof","executionInfo":{"status":"ok","timestamp":1611099907154,"user_tz":300,"elapsed":803,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}}},"source":["from pyspark.ml.feature import Tokenizer\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHYBC46Xjkom","executionInfo":{"status":"ok","timestamp":1611099944795,"user_tz":300,"elapsed":3105,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}}},"source":["# Create sample DataFrame\n","dataframe = spark.createDataFrame([\n","    (0, \"Spark is great\"),\n","    (1, \"We are learning Spark\"),\n","    (2, \"Spark is better than hadoop no doubt\")\n","], [\"id\", \"sentence\"])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DqpXq9MQjkoq","executionInfo":{"status":"ok","timestamp":1611100014864,"user_tz":300,"elapsed":3468,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}},"outputId":"5fe8bdc2-b1bb-454a-e9f6-c65b636e45cb"},"source":["# Show DataFrame\n","dataframe.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O7wJU0_Cjkow","executionInfo":{"status":"ok","timestamp":1611100019378,"user_tz":300,"elapsed":457,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}},"outputId":"78825911-fa15-47e6-b005-6ff6b70ae5e5"},"source":["# Tokenize word\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_aaa12fa7bbd5"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHYnBPMqjko0","executionInfo":{"status":"ok","timestamp":1611100029296,"user_tz":300,"elapsed":1924,"user":{"displayName":"Brendan Cartin","photoUrl":"","userId":"05877746786385659980"}},"outputId":"41e7c7cb-f160-4a82-a627-b71577cd6f4d"},"source":["# Show DataFrame\n","dataframe.show()\n","# Transform and show DataFrame\n","tokenized = tokenizer.transform(dataframe)\n","tokenized.show(truncate=False)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n","+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k92zPWKjkGzp"},"source":[""],"execution_count":null,"outputs":[]}]}